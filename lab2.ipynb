{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2  # Importar regularización L2 desde keras.regularizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('entrenamiento.p', 'rb') as file:\n",
    "    training_data = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('prueba.p', 'rb') as file:\n",
    "    test_data = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('validacion.p', 'rb') as file:\n",
    "    validation_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir la data en X, Y. Entrenamiento, prueba y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[\"features\"]\n",
    "y_train = training_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[\"features\"]\n",
    "y_test = test_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation_data[\"features\"]\n",
    "y_val = test_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar los datos, debido a que los datos están con valores de 0 a 255 al dividirlos por 255 esto nos da un porcentaje de que tanto se acerca a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "X_val = X_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos de entrenamiento y como son labels volverlos en categoricos desde 0 hasta 42, es decir 43 categorias diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train, 43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_val = to_categorical(y_val, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer conjunto de capas\n",
    "\n",
    "### Capa convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una capa convulucional que tiene 32 filtros. Debido a que nuestras imagenesposeen un canal de colres, la forma del input sería de 32, 32, 3 siendo 3 el canal de los colores. Asimismo, el kernel sería de 4 por 4 lo cual quiere decir que se tomaran cuadrados de 4 por 4 pixeles para la capa de convolusión. Esto tendrá como output 32 imagenes diferentes, debido a los 32 filtros cada una de ellas con un tamaño de 29 (tamaño de imagen de entrada - (tamaño de kernel) + 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(Conv2D(filters = 32, kernel_size = (4, 4), input_shape = (32, 32, 3), activation = 'relu',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capa de submuestreo (max-pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una capa que realiza maxpooling. Este método lo que hace es crear una ventana del tamaño que se pida, en nuestro caso es de 2x2. En esa ventana de  4x4 se toma el valor del pixel más alto, es decir el valor maximo dentro de la ventana y luego se crea otra \"imagen\" de valores con ese nuevo valor. Esto se realiza con cada cuadro (2x2) de la imágen input ingresada. El output de esto es una imagen de 14 x 14. Esto se obtuvo a través de: floor((29-poolsize)/stride)+1. Ej. floor((29-2)/2) +1 => floor(27/2) +1 => floor(13.5)+1 => 13+1 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(MaxPool2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo conjunto de capas\n",
    "\n",
    "Debido a que ahora se estan trabajando con colores. La cantidad de datos a procesar son demasiados por lo cual vale la pena realizar otra capa. Tanto convolucional como de submuestreo antes de analizar los datos a través de una red neuronal. \n",
    "\n",
    "### Capa convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(Conv2D(filters = 32, kernel_size = (4, 4), input_shape = (32, 32, 3), activation = 'relu',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capa de sub-muestreo (Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(MaxPool2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256 neuronas para la capa escondida con función de activación de Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(Dense(256, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43 outputs finales debido a que se tienen 43 categorías diferentes. Esta última capa tiene la función de decisión (activación) de Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(Dense(43, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para la compilación del modelo se utilizara la función de perdida de categorical crossentropy. Esta función sirve cuando se tiene una clasificación multi clase el cual es nuestro caso al tener 43 posibles decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 29, 29, 32)        1568      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               205056    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                11051     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234091 (914.42 KB)\n",
      "Trainable params: 234091 (914.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un generador de imágenes con aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentar el tamaño del lote y el número de épocas\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "modelo = Sequential()\n",
    "modelo.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "modelo.add(MaxPool2D(pool_size=(2, 2)))\n",
    "modelo.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "modelo.add(MaxPool2D(pool_size=(2, 2)))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(512, activation='relu'))\n",
    "modelo.add(Dropout(0.5))\n",
    "modelo.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "modelo.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1221611 (4.66 MB)\n",
      "Trainable params: 1221611 (4.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_val = X_val / 255\n",
    "\n",
    "y_cat_train = to_categorical(y_train, 43)\n",
    "y_cat_test = to_categorical(y_test, 43)\n",
    "y_cat_val = to_categorical(y_val, 43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "modelo.add(MaxPool2D(pool_size=(2, 2)))\n",
    "modelo.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "modelo.add(MaxPool2D(pool_size=(2, 2)))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "modelo.add(Dropout(0.5))\n",
    "modelo.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se compila el modelo especificando la función de pérdida (categorical_crossentropy, adecuada para clasificación multiclase), el optimizador (rmsprop en este caso) y las métricas que se desea rastrear durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1221611 (4.66 MB)\n",
      "Trainable params: 1221611 (4.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 1s 3ms/step - loss: 12.1426 - accuracy: 0.0116\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_metrics = modelo.evaluate(X_test, y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtener predicciones del modelo en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.3.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las predicciones a etiquetas (índices de clase)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.00      0.00      0.00       720\n",
      "           2       0.00      0.00      0.00       750\n",
      "           3       0.03      0.15      0.06       450\n",
      "           4       0.00      0.00      0.00       660\n",
      "           5       0.00      0.00      0.00       630\n",
      "           6       0.00      0.00      0.00       150\n",
      "           7       0.06      0.02      0.03       450\n",
      "           8       0.02      0.04      0.02       450\n",
      "           9       0.00      0.00      0.00       480\n",
      "          10       0.00      0.00      0.00       660\n",
      "          11       0.02      0.01      0.01       420\n",
      "          12       0.00      0.00      0.00       690\n",
      "          13       0.00      0.00      0.00       720\n",
      "          14       0.00      0.00      0.00       270\n",
      "          15       0.00      0.00      0.00       210\n",
      "          16       0.00      0.00      0.00       150\n",
      "          17       0.00      0.00      0.00       360\n",
      "          18       0.00      0.00      0.00       390\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.00      0.00      0.00        90\n",
      "          21       0.00      0.00      0.00        90\n",
      "          22       0.00      0.00      0.00       120\n",
      "          23       0.00      0.00      0.00       150\n",
      "          24       0.00      0.00      0.00        90\n",
      "          25       0.00      0.00      0.00       480\n",
      "          26       0.00      0.00      0.00       180\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.04      0.01      0.01       150\n",
      "          29       0.00      0.00      0.00        90\n",
      "          30       0.01      0.03      0.02       150\n",
      "          31       0.00      0.00      0.00       270\n",
      "          32       0.00      0.00      0.00        60\n",
      "          33       0.00      0.00      0.00       210\n",
      "          34       0.00      0.00      0.00       120\n",
      "          35       0.00      0.00      0.00       390\n",
      "          36       0.00      0.00      0.00       120\n",
      "          37       0.00      0.00      0.00        60\n",
      "          38       0.00      0.00      0.00       690\n",
      "          39       0.00      0.00      0.00        90\n",
      "          40       0.00      0.00      0.00        90\n",
      "          41       0.01      0.77      0.01        60\n",
      "          42       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.01     12630\n",
      "   macro avg       0.00      0.02      0.00     12630\n",
      "weighted avg       0.01      0.01      0.00     12630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/priscillagonzalez/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Mostrar un informe de clasificación que incluye precisión, recall y f1-score para cada clase\n",
    "class_report = classification_report(np.argmax(y_cat_test, axis=1), y_pred_labels)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoras y experimentación\n",
    "\n",
    "### - Se podrían ajustar mejor algunas parámetros como lo es la tasa de aprendizaje, el batch size y las épocas que se manejan\n",
    "### - Se podría utilizar regularización como L1 o L2 para evitar el sobreajuste\n",
    "### - También se podría cambiar el tamaño de la imagen para poder observar cómo es que afecta el rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
